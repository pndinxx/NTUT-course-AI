import streamlit as st
import os
import requests
import json
import google.generativeai as genai
from PIL import Image, ImageDraw, ImageFont
import graphviz

# ==========================================
# 0. æ¨¡å‹å®šç¾© (ç­–ç•¥å‡ç´šç‰ˆ)
# ==========================================
# Manager & Judge (å¤§è…¦): ä½¿ç”¨æœ€å¼·çš„ 2.5 Flash è™•ç†è¤‡é›œé‚è¼¯
# Cleaner, Hunter, Fixer (æ‰‹è…³): ä½¿ç”¨ 2.5 Flash-Lite è™•ç†ç°¡æ˜“ä»»å‹™ (æ›´çœè³‡æºã€é€Ÿåº¦æ›´å¿«)
MODELS = {
    "MANAGER": "models/gemini-2.5-flash",       # ä¸­å¤®å¤§è…¦ (åˆ¤æ–·æ„åœ–)
    "JUDGE":   "models/gemini-2.5-flash",       # é¦–å¸­åˆ†æå¸« (æ·±åº¦è©•åˆ†)
    "CLEANER": "models/gemini-2.5-flash-lite",  # è³‡æ–™æ¸…ç† (Lite)
    "HUNTER":  "models/gemini-2.5-flash-lite",  # çµé ­/æ¨è–¦ (Lite)
    "FIXER":   "models/gemini-2.5-flash-lite"   # æ ¼å¼ä¿®å¾© (Lite)
}

# ==========================================
# 1. RAG çŸ¥è­˜åº« (æœ¬åœ°æª”æ¡ˆ)
# ==========================================
def retrieve_local_rag(query):
    file_path = os.path.join(os.path.dirname(__file__), "knowledge.json")
    if not os.path.exists(file_path): return None
    try:
        with open(file_path, "r", encoding='utf-8') as f:
            knowledge_db = json.load(f)
        results = []
        for key, info in knowledge_db.items():
            if key in query: results.append(info)
        if results: return "\n".join(results)
    except: pass
    return None

# ==========================================
# 2. è¨­å®šé é¢èˆ‡ API Keys
# ==========================================
st.set_page_config(page_title="åŒ—ç§‘å¤§AIé¸èª²é¡§å• (Managerç‰ˆ)", layout="wide")

try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    GOOGLE_SEARCH_API_KEY = st.secrets["GOOGLE_SEARCH_API_KEY"]
    SEARCH_ENGINE_ID = st.secrets["SEARCH_ENGINE_ID"]
except:
    GEMINI_API_KEY = None; GOOGLE_SEARCH_API_KEY = None; SEARCH_ENGINE_ID = None

if not GEMINI_API_KEY:
    with st.sidebar:
        st.warning("âš ï¸ è«‹è¼¸å…¥ API Keys")
        GEMINI_API_KEY = st.text_input("Gemini API Key", type="password")
        GOOGLE_SEARCH_API_KEY = st.text_input("Google Search Key", type="password")
        SEARCH_ENGINE_ID = st.text_input("Search Engine ID")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# ==========================================
# 3. æ ¸å¿ƒï¼šé€šç”¨æ¨¡å‹å‘¼å«å™¨
# ==========================================
def call_ai(contents, model_name):
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(contents)
        return response.text
    except Exception as e:
        # Fallback æ©Ÿåˆ¶ï¼šå¦‚æœ Lite æˆ– 2.5 å‡ºéŒ¯ï¼Œé€€å›ç©©å®šçš„ 2.0 Flash
        try:
            print(f"Model {model_name} failed, falling back to 2.0-flash. Error: {e}")
            fallback = genai.GenerativeModel("models/gemini-2.0-flash")
            return fallback.generate_content(contents).text
        except: return None

# ==========================================
# 4. Agent åœ˜éšŠ
# ==========================================

def agent_manager(user_query):
    """
    â˜… ä¸­å¤®å¤§è…¦ (Manager Agent) â˜…
    åˆ¤æ–·ä½¿ç”¨è€…æ„åœ–ï¼Œä¸¦ç²¾ç¢ºæå–ã€Œäººåã€æˆ–ã€Œé—œéµå­—ã€
    """
    prompt = f"""
    ä½¿ç”¨è€…è¼¸å…¥ï¼šã€Œ{user_query}ã€
    
    è«‹åˆ¤æ–·ä½¿ç”¨è€…çš„æ„åœ–ï¼Œä¸¦è¼¸å‡º JSONï¼š
    1. è‹¥è¼¸å…¥åƒ…åŒ…å«ã€Œèª²ç¨‹åç¨±ã€æˆ–ã€Œé¡åˆ¥ã€(å¦‚ï¼šå¾®ç©åˆ†, é«”è‚², ç”œèª²) -> æ„åœ–ç‚º "recommend"
    2. è‹¥è¼¸å…¥åŒ…å«ã€Œç‰¹å®šè€å¸«åå­—ã€(å¦‚ï¼šå¾®ç©åˆ† ç¾…ä»å‚‘, ç¾…ä»å‚‘, å»–xx) -> æ„åœ–ç‚º "analyze"
    
    é‡é»ï¼šåœ¨ "keywords" æ¬„ä½ä¸­ï¼Œå¦‚æœæ„åœ–æ˜¯ "analyze"ï¼Œè«‹åªæå–ã€Œè€å¸«å§“åã€æœ¬èº«ï¼Œä¸è¦åŒ…å«ã€Œè©•åƒ¹ã€ã€ã€Œå¥½å—ã€ç­‰å­—çœ¼ã€‚
    
    å›å‚³æ ¼å¼ï¼š
    {{
        "intent": "recommend" æˆ– "analyze",
        "keywords": "ä¹¾æ·¨çš„æœå°‹ä¸»é«” (äººåæˆ–èª²å)",
        "reason": "åˆ¤æ–·ç†ç”±"
    }}
    """
    res = call_ai(prompt, MODELS["MANAGER"])
    try:
        return json.loads(res.replace("```json","").replace("```","").strip())
    except:
        return {"intent": "recommend", "keywords": user_query, "reason": "è§£æå¤±æ•—ï¼Œé è¨­æ¨è–¦"}

def search_google(query, mode="analysis"):
    """
    â˜… æœå°‹å¼•æ“å‡ç´šç‰ˆ â˜…
    - Analysis æ¨¡å¼ï¼šè§£é– NTUT é™åˆ¶ï¼ŒåŒæ™‚æœå°‹æ ¡å…§è³‡è¨Šèˆ‡å»£åŸŸ Dcard/PTT è¨è«–ã€‚
    - Recommend æ¨¡å¼ï¼šç¶­æŒé–å®šåŒ—ç§‘å¤§ç›¸é—œè¨è«–ã€‚
    """
    if not GOOGLE_SEARCH_API_KEY: return []
    
    # â˜…â˜…â˜… é—œéµä¿®æ”¹ï¼šæœå°‹ç­–ç•¥å‡ç´š â˜…â˜…â˜…
    if mode == "analysis":
        # ç­–ç•¥ï¼š(åŒ—ç§‘å¤§ + è€å¸«) OR (è€å¸« + Dcard/PTT)
        # ä¸åŠ å…¥ã€Œè©•åƒ¹ã€äºŒå­—ï¼Œè®“æœå°‹æ›´å»£æ³›
        q1 = f'"åŒ—ç§‘å¤§" {query}' 
        q2 = f'{query} Dcard PTT'
        final_query = f"({q1}) OR ({q2})"
    else:
        # æ¨è–¦æ¨¡å¼ï¼šæ‰¾åŒ—ç§‘å¤§ç¯„åœå…§çš„å¥½èª²
        final_query = f"åŒ—ç§‘å¤§ {query} æ¨è–¦ ç”œæ¶¼ å¥½é (site:dcard.tw OR site:ptt.cc)"
    
    print(f"ğŸ” Executing Search: {final_query}") # Debug ç”¨

    url = "https://www.googleapis.com/customsearch/v1"
    params = {'key': GOOGLE_SEARCH_API_KEY, 'cx': SEARCH_ENGINE_ID, 'q': final_query, 'num': 8}
    
    try:
        res = requests.get(url, params=params, timeout=10)
        data = res.json()
        if 'items' not in data: return []
        results = []
        for i in data['items']:
            link = i.get('link', '')
            src = "PTT" if "ptt.cc" in link else "Dcard" if "dcard.tw" in link else "Official/Web"
            results.append(f"[{src}] {i.get('title')}\n{i.get('snippet')}")
        return results
    except Exception as e:
        print(f"Search Error: {e}")
        return []

def agent_data_curator(course_name, raw_data):
    """Agent 1: è³‡æ–™æ¸…ç† (ä½¿ç”¨ Lite æ¨¡å‹)"""
    web_context = "\n---\n".join(raw_data)
    rag_info = retrieve_local_rag(course_name)
    rag_text = f"\n### ğŸ« æ ¡å…§RAGè³‡è¨Š:\n{rag_info}\n" if rag_info else ""

    prompt = f"""
    ä½ æ˜¯è³‡æ–™æ¸…ç†å°ˆå®¶ã€‚æŸ¥è©¢ç›®æ¨™ï¼šã€Œ{course_name}ã€ã€‚
    è«‹å»é™¤ç„¡é—œå»£å‘Šã€‚
    
    **é‡è¦æŒ‡ä»¤**ï¼š
    1. è‹¥è³‡æ–™åŒ…å«è©²è€å¸«åœ¨ã€Œå…¶ä»–å­¸æ ¡ã€(å¦‚å°ç§‘ã€æˆå¤§ç­‰) çš„è©•åƒ¹ï¼Œå‹™å¿…ä¿ç•™ï¼Œé€™å°è©•ä¼°è€å¸«é¢¨æ ¼è‡³é—œé‡è¦ã€‚
    2. æ‘˜è¦é‡é»ï¼šè©•åˆ†é¢¨æ ¼ã€é»åé »ç‡ã€ä½œæ¥­é‡ã€å€‹æ€§ã€‚
    
    {rag_text}
    åŸå§‹è³‡æ–™ï¼š{web_context}
    è«‹ç›´æ¥è¼¸å‡ºç²¾ç°¡æ‘˜è¦ (Markdownæ ¼å¼)ï¼š
    """
    return call_ai(prompt, MODELS["CLEANER"])

def agent_analyst(course_name, curated_data):
    """Agent 2: è©•åˆ†åˆ†æ (ä½¿ç”¨ Pro/Flash é«˜æ™ºå•†æ¨¡å‹)"""
    prompt = f"""
    ä½ æ˜¯åš´æ ¼çš„é¸èª²åˆ†æå¸«ã€‚åˆ†æç›®æ¨™ï¼šã€Œ{course_name}ã€ã€‚
    è³‡æ–™ï¼š{curated_data}
    
    è«‹é€²è¡Œ 0-100 åˆ†è©•ç´šã€‚
    **æ³¨æ„ï¼šè«‹ç¶œåˆåƒè€ƒè©²è€å¸«åœ¨åŒ—ç§‘å¤§åŠéå¾€å…¶ä»–å­¸æ ¡(è‹¥æœ‰)çš„è©•åƒ¹ã€‚**
    
    è«‹è¼¸å‡º JSON: 
    {{
        "rank": "ç¨±è™Ÿ (e.g. ä½›å¿ƒ, å¤§åˆ€, æœ­å¯¦)", 
        "tier": "S/A/B/C/D", 
        "score": åˆ†æ•¸(int), 
        "reason": "ä¸€å¥è©±çŸ­è©•", 
        "tags": ["ç‰¹å¾µ1", "ç‰¹å¾µ2"], 
        "details": "è©³ç´°èªªæ˜(è‹¥æœ‰åƒè€ƒå¤–æ ¡è©•åƒ¹è«‹ç‰¹åˆ¥è¨»æ˜)"
    }}
    """
    return call_ai(prompt, MODELS["JUDGE"])

def agent_recommender(category, raw_data):
    """Agent 4: æ¨è–¦æ¸…å–® (ä½¿ç”¨ Lite æ¨¡å‹)"""
    web_context = "\n---\n".join(raw_data)
    prompt = f"""
    ä½¿ç”¨è€…æƒ³æ‰¾ã€Œ{category}ã€çš„å¥½èª²ã€‚
    è³‡æ–™ï¼š{web_context}
    
    è«‹æ‰¾å‡º **æœ€æ¨è–¦çš„ 3 ä½** è€å¸«æˆ–èª²ç¨‹ã€‚
    è«‹è¼¸å‡º JSON List: 
    [
        {{"teacher": "è€å¸«å", "subject": "èª²ç¨‹å", "reason": "æ¨è–¦ç†ç”±", "stars": 1-5}}
    ]
    """
    return call_ai(prompt, MODELS["HUNTER"])

def agent_fixer(raw_text, is_list=False):
    """Agent 3: æ ¼å¼ä¿®å¾© (ä½¿ç”¨ Lite æ¨¡å‹)"""
    try:
        clean = raw_text.replace("```json","").replace("```","").strip()
        return json.loads(clean)
    except:
        # Lite æ¨¡å‹ä¿®å¾© JSON ä¹Ÿç¶½ç¶½æœ‰é¤˜
        res = call_ai(f"Return only valid JSON based on this:\n{raw_text}", MODELS["FIXER"])
        try: return json.loads(res.replace("```json","").replace("```","").strip())
        except: return None

# ==========================================
# 5. UI èˆ‡ åŸ·è¡Œé‚è¼¯
# ==========================================
st.title("ğŸ“ åŒ—ç§‘å¤§ AI é¸èª²é¡§å• (Proç‰ˆ)")
st.caption(f"ğŸš€ Powered by {MODELS['MANAGER']} & {MODELS['CLEANER']} | æ™ºèƒ½æ„åœ–è­˜åˆ¥ | å»£åŸŸæœå°‹")

if 'analysis_result' not in st.session_state: st.session_state.analysis_result = None
if 'recommend_result' not in st.session_state: st.session_state.recommend_result = None

c1, c2 = st.columns([4, 1])
with c1: 
    user_input = st.text_input("æƒ³å•ä»€éº¼ï¼Ÿ", placeholder="è¼¸å…¥ã€Œå¾®ç©åˆ†ã€æ¨è–¦å¥½èª²ï¼Œæˆ–ã€Œå¾®ç©åˆ† ç¾…ä»å‚‘ã€åˆ†æè©•åƒ¹")
with c2: 
    btn_search = st.button("ğŸ” æ™ºèƒ½æœå°‹", use_container_width=True, type="primary")

if btn_search and user_input:
    if not GEMINI_API_KEY: st.error("è«‹è¨­å®š API Key"); st.stop()
    
    # 1. Manager æ€è€ƒ
    with st.status("ğŸ§  Manager æ­£åœ¨æ€è€ƒæ‚¨çš„æ„åœ–...", expanded=True) as status:
        intent_data = agent_manager(user_input)
        intent = intent_data.get("intent", "recommend")
        keywords = intent_data.get("keywords", user_input)
        
        if intent == "analyze":
            st.info(f"ğŸ’¡ è­˜åˆ¥æ„åœ–ï¼š**åˆ†æç‰¹å®šè€å¸«/èª²ç¨‹** (ç›®æ¨™ï¼š{keywords})")
            st.write("ğŸ” å•Ÿå‹•å»£åŸŸæœå°‹å¼•æ“ (æ ¡å…§ + Dcard/PTT å»£åŸŸ)...")
            
            # åŸ·è¡Œåˆ†ææµç¨‹
            raw_data = search_google(keywords, mode="analysis")
            if not raw_data:
                st.warning("æ‰¾ä¸åˆ°ç›¸é—œè³‡æ–™ï¼Œè«‹æª¢æŸ¥è€å¸«åå­—æ˜¯å¦æ­£ç¢ºã€‚")
                status.update(label="æœå°‹ç„¡çµæœ", state="error")
                st.stop()

            st.write(f"ğŸ§¹ è³‡æ–™æ¸…æ´— (ä½¿ç”¨ {MODELS['CLEANER']})...")
            curated = agent_data_curator(keywords, raw_data)
            
            st.write(f"âš–ï¸ æ·±åº¦è©•åˆ† (ä½¿ç”¨ {MODELS['JUDGE']})...")
            raw_res = agent_analyst(keywords, curated)
            final_data = agent_fixer(raw_res)
            
            if final_data:
                st.session_state.analysis_result = final_data
                st.session_state.recommend_result = None
                status.update(label="åˆ†æå®Œæˆ", state="complete")
            else:
                status.update(label="åˆ†æå¤±æ•—", state="error")
                
        else:
            st.info(f"ğŸ’¡ è­˜åˆ¥æ„åœ–ï¼š**æ¨è–¦å¥½èª²æ¸…å–®** (ç›®æ¨™ï¼š{keywords})")
            st.write("ğŸ” æœå°‹åŒ—ç§‘å¤§ç†±é–€èª²ç¨‹...")
            
            # åŸ·è¡Œæ¨è–¦æµç¨‹
            raw_data = search_google(keywords, mode="recommend")
            st.write(f"ğŸ•µï¸ çµé ­ç¯©é¸ (ä½¿ç”¨ {MODELS['HUNTER']})...")
            raw_res = agent_recommender(keywords, raw_data)
            final_list = agent_fixer(raw_res, is_list=True)
            
            if final_list:
                st.session_state.recommend_result = final_list
                st.session_state.analysis_result = None
                status.update(label="æ¨è–¦å®Œæˆ", state="complete")
            else:
                status.update(label="æ¨è–¦å¤±æ•—", state="error")

# === çµæœé¡¯ç¤ºå€ ===

# 1. åˆ†æçµæœ
if st.session_state.analysis_result:
    d = st.session_state.analysis_result
    st.divider()
    
    c_score, c_info = st.columns([1, 2])
    with c_score:
        st.metric("AI è©•åˆ†", f"{d.get('score')} åˆ†", d.get('tier'))
        st.markdown(f"### {d.get('rank')}")
    with c_info:
        st.success(f"ğŸ’¬ {d.get('reason')}")
        st.write(d.get('details'))
        st.write("ğŸ·ï¸ " + " ".join([f"`{t}`" for t in d.get('tags', [])]))

    st.divider()
    st.subheader("ğŸ•¸ï¸ è©•åƒ¹é—œè¯åœ–")
    g = graphviz.Digraph(attr={'rankdir':'LR', 'bgcolor':'transparent'})
    g.node(user_input, shape='doublecircle', style='filled', fillcolor='#E1F5FE')
    g.node(d['tier'], shape='circle', style='filled', fillcolor='#FFF9C4')
    g.edge(user_input, d['tier'], label=str(d['score']))
    for t in d.get('tags', []):
        g.node(t, shape='ellipse', style='filled', fillcolor='#F5F5F5')
        g.edge(user_input, t)
    st.graphviz_chart(g)

# 2. æ¨è–¦çµæœ
if st.session_state.recommend_result:
    st.divider()
    st.subheader(f"âœ¨ æ ¹æ“šã€Œ{user_input}ã€ç‚ºæ‚¨æ¨è–¦ï¼š")
    cols = st.columns(3)
    for i, r in enumerate(st.session_state.recommend_result):
        with cols[i%3]:
            with st.container(border=True):
                st.markdown(f"### ğŸ† {r.get('teacher')}")
                st.caption(f"èª²ç¨‹: {r.get('subject')}")
                st.write(f"æ¨è–¦åº¦: {'â­'*int(r.get('stars', 3))}")
                st.info(r.get('reason'))
                if st.button(f"è©³ç´°åˆ†æ {r.get('teacher')}", key=f"rec_{i}"):
                     st.info(f"è«‹åœ¨æœå°‹æ¬„è¼¸å…¥ã€Œ{r.get('teacher')}ã€é€²è¡Œè©³ç´°åˆ†æï¼")
